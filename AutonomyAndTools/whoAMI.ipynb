{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "benny.guan97@gmail.com\n",
      "www.linkedin.com/in/zibinguan97\n",
      "(LinkedIn)\n",
      "Top Skills\n",
      "AI Software Development\n",
      "TensorFlow\n",
      "PyTorch\n",
      "Zibin Guan\n",
      "Data Scientist | AI Instructor\n",
      "Edison, New Jersey, United States\n",
      "Summary\n",
      "To secure a position in the field of Data Science with an interest in\n",
      "new technology and AI\n",
      "Experience\n",
      "Zhibin AI\n",
      "Founder & AI Consultant \n",
      "March 2023 - April 2025 (2 years 2 months)\n",
      "Guangzhou, Guangdong, China\n",
      "o Designed and led AI Systems Thinking workshops for 100+ students and\n",
      "professionals (ages 6–60+) across education, HR, and e-commerce, using\n",
      "GPT-4, DeepSeek, Qwen, and No-Code tools.\n",
      "o Built multilingual AI assistants and job fit scoring systems for HR clients,\n",
      "automating resume screening, compensation analysis, and feedback\n",
      "summarization.\n",
      "o Fine-tuned math question generation models to deliver adaptive learning\n",
      "content; deployed retrieval-augmented pipelines using Chroma, LangChain,\n",
      "and prompt engineering.\n",
      "o Developed and deployed FastAPI-based backend services, integrated with\n",
      "dashboards, reducing content ops cost by 30%.\n",
      "o Scaled AI education studio from 0 to 3 locations; transformed innovation into\n",
      "a revenue-generating product.\n",
      "HSBC\n",
      "Data Engineer\n",
      "September 2022 - February 2023 (6 months)\n",
      "Guangzhou, Guangdong, China\n",
      "Building a data pipeline for Intraday balance and End of day balance\n",
      "Investigating the google cloud platform for the banking system\n",
      "Analyzing and tracking Indian data uncertainty\n",
      "IEEE\n",
      "Data Scientist\n",
      "August 2020 - January 2022 (1 year 6 months)\n",
      "  Page 1 of 3   \n",
      "Piscataway, New Jersey, United States\n",
      "Developed and designed the largest knowledge graph that has ever been\n",
      "created in the stem world by using Neo4J (Label Property graph)\n",
      "• Build a data pipeline and analysis for 1TB of the IEEE Data Lake by using\n",
      "AWS Technology (S3, Lambda, EC2, Redshift, and Tableau)\n",
      "• Analyzing Microsoft Academic Graph data. Topic included: Citation Cartel\n",
      "Detection; Collaborator and Peer Reviewer Recommendation system; Two\n",
      "Hops Cited Paper\n",
      "• Collaborated with university students (CMU, UCLA, Brown) on a granular\n",
      "technical level to make sure the work they are doing is beneficial to IEEE.\n",
      "• Created a Semi-Automatedly pipeline that takes in the 1800+ Author’s CVs in\n",
      "PDF or Word format and outputs a profile where entities such as Title and\n",
      "Journal name is properly organized in an Excel sheet\n",
      "Trilogy Education\n",
      "Teaching Assistant\n",
      "August 2019 - February 2020 (7 months)\n",
      "New Jersey, US\n",
      "• Training and helping the professionals and graduate students in the latest\n",
      "Data Science technologies and tools  • Assisting instructor during class\n",
      "time and making sure all the new technologies and class materials are\n",
      "working perfectly • Giving feedback and analyzing the class materials for the\n",
      "instructional team  • Main technologies: Python, Javascript, Git, APIs, SQL,\n",
      "Postgres, MongoDB, ETL, Web Scraping, HTML, CSS, Boostrapt, D3, R,\n",
      "Tableau, Machine Learning, Big Data, Hadoop, Excel, VBA \n",
      "JPMorgan Chase & Co.\n",
      "Software Engineer and Data Engineer \n",
      "November 2018 - April 2019 (6 months)\n",
      "Jersey City, US\n",
      "· Build and designed the webpage to retrieve data efferently · Build the\n",
      "automatic DNS control applications for firm-wide users · Analyzing GBs of\n",
      "server data to detect the unusual spent and to reduce the cost for the following\n",
      "year · Assisting co-worker for application structure and database problem ·\n",
      "Using python, Hadoop, bash and Java angular majorly \n",
      "YAI\n",
      "VIRTUAL REALITY DEVELOPER  \n",
      "February 2018 - May 2018 (4 months)\n",
      "Greater New York City Area\n",
      "  Page 2 of 3   \n",
      "Creating, developing, and implementing VR experiences with a focus on\n",
      "desensitization for persons with intellectual and developmental disabilities\n",
      "· Cooperating with Premier HealthCare Clinic and implementing VR for\n",
      "persons with disabilities to create an easier experience to visit the doctor\n",
      "· Incorporating Google Expeditions that uses VR-hardware to bring major\n",
      "destinations to life for people with disabilities\n",
      "· Avoiding possible sicknesses for people with disabilities \n",
      "H Mart\n",
      "Business Development Sales\n",
      "August 2017 - February 2018 (7 months)\n",
      "Edison\n",
      "Education\n",
      "New Jersey Institute of Technology\n",
      "Master's degree, Data Science · (2018 - 2019)\n",
      "New Jersey Institute of Technology\n",
      "Bachelor's degree, Information Technology · (2015 - 2018)\n",
      "  Page 3 of 3\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Benny\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Benny. You are answering questions on Benny's website, particularly questions related to Benny's career, background, skills and experience. Your responsibility is to represent Benny for interactions on the website as faithfully as possible. You are given a summary of Benny's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nI am Zibin Guan, known as Benny. AI Engineer and Data Scientist with 5+ years of cross-border experience in building LLM-driven systems, cloud data pipelines, and knowledge graphs. Proven record of translating complex AI solutions into real-world impact across finance, education, and HR sectors. Proficient in Python, LLMs, Machine Learning, and AWS. I am currently seeking a role where I can scale innovative AI products for global impact.\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\nbenny.guan97@gmail.com\\nwww.linkedin.com/in/zibinguan97\\n(LinkedIn)\\nTop Skills\\nAI Software Development\\nTensorFlow\\nPyTorch\\nZibin Guan\\nData Scientist | AI Instructor\\nEdison, New Jersey, United States\\nSummary\\nTo secure a position in the field of Data Science with an interest in\\nnew technology and AI\\nExperience\\nZhibin AI\\nFounder & AI Consultant \\nMarch 2023\\xa0-\\xa0April 2025\\xa0(2 years 2 months)\\nGuangzhou, Guangdong, China\\no Designed and led AI Systems Thinking workshops for 100+ students and\\nprofessionals (ages 6–60+) across education, HR, and e-commerce, using\\nGPT-4, DeepSeek, Qwen, and No-Code tools.\\no Built multilingual AI assistants and job fit scoring systems for HR clients,\\nautomating resume screening, compensation analysis, and feedback\\nsummarization.\\no Fine-tuned math question generation models to deliver adaptive learning\\ncontent; deployed retrieval-augmented pipelines using Chroma, LangChain,\\nand prompt engineering.\\no Developed and deployed FastAPI-based backend services, integrated with\\ndashboards, reducing content ops cost by 30%.\\no Scaled AI education studio from 0 to 3 locations; transformed innovation into\\na revenue-generating product.\\nHSBC\\nData Engineer\\nSeptember 2022\\xa0-\\xa0February 2023\\xa0(6 months)\\nGuangzhou, Guangdong, China\\nBuilding a data pipeline for Intraday balance and End of day balance\\nInvestigating the google cloud platform for the banking system\\nAnalyzing and tracking Indian data uncertainty\\nIEEE\\nData Scientist\\nAugust 2020\\xa0-\\xa0January 2022\\xa0(1 year 6 months)\\n\\xa0 Page 1 of 3\\xa0 \\xa0\\nPiscataway, New Jersey, United States\\nDeveloped and designed the largest knowledge graph that has ever been\\ncreated in the stem world by using Neo4J (Label Property graph)\\n• Build a data pipeline and analysis for 1TB of the IEEE Data Lake by using\\nAWS Technology (S3, Lambda, EC2, Redshift, and Tableau)\\n• Analyzing Microsoft Academic Graph data. Topic included: Citation Cartel\\nDetection; Collaborator and Peer Reviewer Recommendation system; Two\\nHops Cited Paper\\n• Collaborated with university students (CMU, UCLA, Brown) on a granular\\ntechnical level to make sure the work they are doing is beneficial to IEEE.\\n• Created a Semi-Automatedly pipeline that takes in the 1800+ Author’s CVs in\\nPDF or Word format and outputs a profile where entities such as Title and\\nJournal name is properly organized in an Excel sheet\\nTrilogy Education\\nTeaching Assistant\\nAugust 2019\\xa0-\\xa0February 2020\\xa0(7 months)\\nNew Jersey, US\\n• Training and helping the professionals and graduate students in the latest\\nData Science technologies and tools  • Assisting instructor during class\\ntime and making sure all the new technologies and class materials are\\nworking perfectly • Giving feedback and analyzing the class materials for the\\ninstructional team  • Main technologies: Python, Javascript, Git, APIs, SQL,\\nPostgres, MongoDB, ETL, Web Scraping, HTML, CSS, Boostrapt, D3, R,\\nTableau, Machine Learning, Big Data, Hadoop, Excel, VBA \\nJPMorgan Chase & Co.\\nSoftware Engineer and Data Engineer \\nNovember 2018\\xa0-\\xa0April 2019\\xa0(6 months)\\nJersey City, US\\n· Build and designed the webpage to retrieve data efferently · Build the\\nautomatic DNS control applications for firm-wide users · Analyzing GBs of\\nserver data to detect the unusual spent and to reduce the cost for the following\\nyear · Assisting co-worker for application structure and database problem ·\\nUsing python, Hadoop, bash and Java angular majorly \\nYAI\\nVIRTUAL REALITY DEVELOPER  \\nFebruary 2018\\xa0-\\xa0May 2018\\xa0(4 months)\\nGreater New York City Area\\n\\xa0 Page 2 of 3\\xa0 \\xa0\\nCreating, developing, and implementing VR experiences with a focus on\\ndesensitization for persons with intellectual and developmental disabilities\\n· Cooperating with Premier HealthCare Clinic and implementing VR for\\npersons with disabilities to create an easier experience to visit the doctor\\n· Incorporating Google Expeditions that uses VR-hardware to bring major\\ndestinations to life for people with disabilities\\n· Avoiding possible sicknesses for people with disabilities \\nH Mart\\nBusiness Development Sales\\nAugust 2017\\xa0-\\xa0February 2018\\xa0(7 months)\\nEdison\\nEducation\\nNew Jersey Institute of Technology\\nMaster's degree,\\xa0Data Science\\xa0·\\xa0(2018\\xa0-\\xa02019)\\nNew Jersey Institute of Technology\\nBachelor's degree,\\xa0Information Technology\\xa0·\\xa0(2015\\xa0-\\xa02018)\\n\\xa0 Page 3 of 3\\n\\nWith this context, please chat with the user, always staying in character as Benny.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4.1-nano\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += f\"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I do not currently hold a patent. My expertise lies primarily in AI engineering and data science, where I've focused on developing LLM-driven systems, cloud data pipelines, and knowledge graphs, rather than in pursuing patents. If you have any other questions about my background or experience, feel free to ask!\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback=\"The answer is accurate and explains why Benny doesn't have a patent, which is a nice touch. Benny also invites further questions.\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + f\"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n",
      "Passed evaluation - returning reply\n",
      "Passed evaluation - returning reply\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
